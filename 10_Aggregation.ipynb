{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technique: 10 Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96af856",
   "metadata": {},
   "source": [
    "### What is this?\n",
    "Aggregation means replacing many small, detailed records with a few summary numbers. For example, instead of every bus stop event, we store one total number for the whole hour.\n",
    "\n",
    "### Why use it?\n",
    "1. **Save Space**: It costs a lot of money to store millions of rows.\n",
    "2. **Faster Analysis**: It is much faster to check a monthly total than a million daily rows.\n",
    "3. **See Trends**: It helps us see the \"Big Picture\" (like the morning rush hour).\n",
    "\n",
    "### Methods:\n",
    "* **Time Aggregation**: Grouping data by minute, hour, day, or week.\n",
    "* **Aggregate Functions**: Using math like `SUM()`, `AVERAGE()`, or `COUNT()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Data (Per Minute):\n",
      "            Timestamp  Transaction_Amount\n",
      "0 2025-06-13 00:00:00            3.257499\n",
      "1 2025-06-13 00:01:00           68.050678\n",
      "2 2025-06-13 00:02:00            8.111841\n",
      "3 2025-06-13 00:03:00           27.766274\n",
      "4 2025-06-13 00:04:00           13.867245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_generator import generate_dtt_dataset, GLOBAL_SEED\n",
    "\n",
    "# 1. Get the data\n",
    "df = generate_dtt_dataset(n_samples=1000)\n",
    "\n",
    "# 2. Create a fake \"Timestamp\" column for 1000 transactions\n",
    "# We use 'min' instead of 'T' for minutes\n",
    "df['Timestamp'] = pd.date_range(start='2025-06-13', periods=1000, freq='min')\n",
    "\n",
    "# 3. Look at the detailed data\n",
    "print(\"Detailed Data (Per Minute):\")\n",
    "print(df[['Timestamp', 'Transaction_Amount']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c89e2",
   "metadata": {},
   "source": [
    "## Grouping the Data\n",
    "We will \"roll up\" the per-minute data into **Hourly** summaries. We will use `SUM` to find the total money and `MEAN` to find the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd4dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Data (Per Hour):\n",
      "                             sum       mean  count\n",
      "Timestamp                                         \n",
      "2025-06-13 00:00:00  1791.047133  29.850786     60\n",
      "2025-06-13 01:00:00  1757.387171  29.289786     60\n",
      "2025-06-13 02:00:00  2134.974297  35.582905     60\n",
      "2025-06-13 03:00:00  2315.036339  38.583939     60\n",
      "2025-06-13 04:00:00  2634.622695  43.910378     60\n",
      "\n",
      "Original rows: 1000\n",
      "Reduced (Aggregated) rows: 17\n"
     ]
    }
   ],
   "source": [
    "# 1. Set the Timestamp as the index to use time tools\n",
    "# Note: Only run this once. If 'Timestamp' is already the index, skip this line.\n",
    "if df.index.name != 'Timestamp':\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# 2. Resample to 'h' (Hourly) and calculate summaries\n",
    "# We use lowercase 'h' instead of 'H'\n",
    "df_hourly = df['Transaction_Amount'].resample('h').agg(['sum', 'mean', 'count'])\n",
    "\n",
    "# 3. Check the results\n",
    "print(\"Aggregated Data (Per Hour):\")\n",
    "print(df_hourly.head())\n",
    "\n",
    "# 4. Compare the size\n",
    "print(f\"\\nOriginal rows: {len(df)}\")\n",
    "print(f\"Reduced (Aggregated) rows: {len(df_hourly)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e1e3c6",
   "metadata": {},
   "source": [
    "## Grouping by Category\n",
    "We can also aggregate by other groups, like **Education_Level**, to see the average salary for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6329ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Salary by Education Level:\n",
      "Education_Level\n",
      "Bachelor       51945.814646\n",
      "High School    50497.493868\n",
      "Master         52870.334908\n",
      "PhD            51256.407442\n",
      "Name: Annual_Salary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by Education and find the Average Salary\n",
    "edu_summary = df.groupby('Education_Level')['Annual_Salary'].mean()\n",
    "\n",
    "print(\"Average Salary by Education Level:\")\n",
    "print(edu_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574fe65",
   "metadata": {},
   "source": [
    "### Summary from Lecture Slides:\n",
    "* **Storage Space**: We save a lot of storage by not keeping every tiny detail forever.\n",
    "* **Efficiency**: Moving from \"per-minute\" to \"hourly\" makes the dataset smaller and more valuable for strategy.\n",
    "* **Trade-off**: We lose the very small details, but we gain a lot of speed and clear trends.\n",
    "\n",
    "This process moves us from \"Raw Data\" to \"Strategic Information\"!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTTvenv (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
